{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSTS Assignment 2\n",
    "## On-Cloud Notebook \n",
    "\n",
    "### Alan Gaugler\n",
    "### U885853\n",
    "### November 3, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Predicting Airplane Delays\n",
    "\n",
    "The goals of this notebook are:\n",
    "- Process and create a dataset from downloaded ZIP files\n",
    "- Exploratory data analysis (EDA)\n",
    "- Establish a baseline model and improve it\n",
    "\n",
    "## Introduction to business scenario\n",
    "You work for a travel booking website that is working to improve the customer experience for flights that were delayed. The company wants to create a feature to let customers know if the flight will be delayed due to weather when the customers are booking the flight to or from the busiest airports for domestic travel in the US. \n",
    "\n",
    "You are tasked with solving part of this problem by leveraging machine learning to identify whether the flight will be delayed due to weather. You have been given access to the a dataset of on-time performance of domestic flights operated by large air carriers. You can use this data to train a machine learning model to predict if the flight is going to be delayed for the busiest airports.\n",
    "\n",
    "### Dataset\n",
    "The provided dataset contains scheduled and actual departure and arrival times reported by certified US air carriers that account for at least 1 percent of domestic scheduled passenger revenues. The data was collected by the Office of Airline Information, Bureau of Transportation Statistics (BTS). The dataset contains date, time, origin, destination, airline, distance, and delay status of flights for flights between 2014 and 2018.\n",
    "The data are in 60 compressed files, where each file contains a CSV for the flight details in a month for the five years (from 2014 - 2018). The data can be downloaded from this link: [https://ucstaff-my.sharepoint.com/:f:/g/personal/ibrahim_radwan_canberra_edu_au/Er0nVreXmihEmtMz5qC5kVIB81-ugSusExPYdcyQTglfLg?e=bNO312]. Please download the data files and place them on a relative path. Dataset(s) used in this assignment were compiled by the Office of Airline Information, Bureau of Transportation Statistics (BTS), Airline On-Time Performance Data, available with the following link: [https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepare the environment \n",
    "\n",
    "Use one of the labs which we have practised on with the Amazon Sagemakers where you perform the following steps:\n",
    "1. Start a lab. - **Done**\n",
    "2. Create a notebook instance and name it \"oncloudproject\". - **Done**\n",
    "3. Increase the used memory to 25 GB from the additional configurations. - **Done**\n",
    "4. Open Jupyter Lab and upload this notebook into it. - **Done**\n",
    "5. Upload the two combined CSV files (combined_csv_v1.csv and combined_csv_v2.csv), which you created in Part A of this project. - **See below**\n",
    "\n",
    "The two CSV files were zipped, uploaded into the working directory and then unzipped. They are read in as CSV files as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import warnings, requests, zipfile, io\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prefix.  This is effectively a directory in S3\n",
    "prefix = 'sagemaker/flight-delay-prediction'\n",
    "\n",
    "# Get the default bucket for SageMaker in the current region\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "print(f\"Data will be uploaded to: s3://{bucket}/{prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2 CSV files\n",
    "df1 = pd.read_csv('combined_csv_v1.csv')\n",
    "df2 = pd.read_csv('combined_csv_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that the files are loaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the header of df1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the target value counts\n",
    "df1['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the target value counts as percentages\n",
    "df1['target'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the header of df1\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the target value counts\n",
    "df2['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the target value counts as percentages\n",
    "df2['target'].value_counts(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files have been successfully loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create functions to calculate the model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class labels\n",
    "class_labels = ['No Delay', 'Delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "def plot_confusion_matrix(y_test, predicted_labels, class_labels):\n",
    "    cm1 = confusion_matrix(y_test, predicted_labels)\n",
    "    plt.figure(figsize=(3.5,3.5))\n",
    "    sns.heatmap(cm1, annot=True, fmt='g', cbar=False,\n",
    "    xticklabels=class_labels,\n",
    "    yticklabels=class_labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the ROC Curve\n",
    "def plot_roc(y_test, predicted_labels):\n",
    "    # Determine the false positive rate, true positive rate and thresholds\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predicted_labels)\n",
    "    \n",
    "    # Calculate the area under the curve\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    # Plot the ROC\n",
    "    plt.plot(fpr, tpr, color='orange', lw=2, label=f'ROC curve, AUC = {round(roc_auc,2)}')\n",
    "    # Plot the line of no discrimination (45 degree angle)\n",
    "    plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the performance metrics\n",
    "def plot_metrics(y_test, predicted_labels)    \n",
    "    # Calcualte true/false positves/negatives\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predicted_labels).ravel()\n",
    "    # Calculate the specificity\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Print the evaluation metrics\n",
    "    print('Evaluation Metrics')\n",
    "    print('------------------')\n",
    "    print('Accuracy: {:.5f}'.format(accuracy_score(test_labels, predicted_labels)))\n",
    "    print('Precision: {:.5f}'.format(precision_score(test_labels, predicted_labels)))\n",
    "    print('Recall (Sensitivity): {:.5f}'.format(recall_score(test_labels, predicted_labels)))\n",
    "    print(f'Specificity: {specificity:.5f}')\n",
    "    print('F1-score: {:.5f}'.format(f1_score(test_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts the input values into a binary value\n",
    "# according to the threshold. I have set it to 0.5 as default.\n",
    "def binary_convert(x):\n",
    "    threshold = 0.5\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# This function will use regular expressions to obtain the probability score of the \n",
    "# predicted target value belonging to class 1 or 0.\n",
    "def get_prob_score(value):\n",
    "    match = re.search(r\"score:([\\d\\.]+)\\}\", value)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 2: Build and evaluate simple models\n",
    "\n",
    "Write code to perform the follwoing steps:\n",
    "1. Split data into training, validation and testing sets (70% - 15% - 15%).\n",
    "2. Use linear learner estimator to build a classifcation model.\n",
    "3. Host the model on another instance\n",
    "4. Perform batch transform to evaluate the model on testing data\n",
    "5. Report the performance metrics that you see better test the model performance \n",
    "\n",
    "Note: You are required to perform the above steps on the two combined datasets separatey and to comments on the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">combined_csv_v1.csv</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Split data into training, validation and testing sets (70% - 15% - 15%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the target column position** \n",
    "\n",
    "The dataframe must have the target value in the first column.\n",
    "\n",
    "Confirm if it is in the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is indeed in the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the train set. Stratifty the target variable for an even distribution.\n",
    "train, test_and_validate = train_test_split(df1, test_size=0.3,\n",
    "                            random_state=12, stratify=df1['target'])\n",
    "\n",
    "# Split the further into the test and validation sets\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5,\n",
    "                              random_state=12, stratify=test_and_validate['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape of the three datasets\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the classes\n",
    "print(train['target'].value_counts())\n",
    "print(test['target'].value_counts())\n",
    "print(validate['target'].value_counts())\n",
    "print()\n",
    "# As percentages\n",
    "print(train['target'].value_counts(1))\n",
    "print(test['target'].value_counts(1))\n",
    "print(validate['target'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an even distribution among the three sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use linear learner estimator to build a classifcation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AWS Linear Learner for binary classification\n",
    "from sagemaker import image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a prefix for the S3 bucket directories\n",
    "prefix='lab3'\n",
    "\n",
    "# Define the train test and validation file names\n",
    "train_file='train.csv'\n",
    "test_file='test.csv'\n",
    "validate_file='validate.csv'\n",
    "\n",
    "# Initialise a connection to the S3 bucket using boto3\n",
    "s3_resource = boto3.Session().resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to upload a given dataframe as a CSV file to a S3 bucket\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    # Crate a text stream in the memory\n",
    "    csv_buffer = io.StringIO()\n",
    "    # Save the df as a CSV file and store in the buffer\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    # Upload the content of the CSV buffer to the desired S3 location\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the three datasets to S3\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the Linear Learner image\n",
    "container = image_uris.retrieve('linear-learner', boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "# Set the hyperparameters for the LL model\n",
    "hyperparams = {\n",
    "    \"feature_dim\": train.shape[1] - 1, # Exclude the target column\n",
    "    \"predictor_type\": \"binary_classifier\",\n",
    "    \"mini_batch_size\": 1000} # A larger batch size of 1000 decreases training time\n",
    "\n",
    "# Define the S3 location to save model outputs\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "\n",
    "# Initialize the Linear Learner estimator using SageMaker's estimator API\n",
    "ll_1=sagemaker.estimator.Estimator(container, # Container image defined above\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1, # One training instance\n",
    "                                       instance_type='ml.c5.9xlarge', # Compute optimized instance is set\n",
    "                                       output_path=s3_output_location, # Output path defined above\n",
    "                                        hyperparameters=hyperparams, # Hyperparams defined above\n",
    "                                        sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Host the model on another instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is set up to be hosted on instance_type 'ml.c5.9xlarge' as defined in the estimator above and in the transformer object below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training data location and the content type\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "# Set the validation data location and the content type\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "# Create a dictionary to hold the training and validation data channels\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the defined data channels. \n",
    "# logs are disabled as they produce a large output\n",
    "ll_1.fit(inputs=data_channels, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Perform batch transform to evaluate the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all columns except the first one from the test dataset except the target variable (1st column)\n",
    "batch_X = test.iloc[:,1:];\n",
    "\n",
    "# Set the filename for the batch input data to be uploaded to S3\n",
    "batch_X_file='batch-in.csv'\n",
    "\n",
    "# Upload the batch input data to S3 using the previously created function\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the S3 path to save the batch transform output\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "\n",
    "# Set the S3 path for the batch input data\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "# Initialize the transformer object\n",
    "ll_1_transformer = ll_1.transformer(instance_count=1,\n",
    "                                       instance_type='ml.c5.9xlarge', # Instance type is set\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line', # Line up the results\n",
    "                                       output_path=batch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the batch transform with the initialized transformer object\n",
    "ll_1_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "\n",
    "# Wait for the batch transform job to finish processing\n",
    "ll_1_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Obtain the output results of the batch transform job from S3\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "\n",
    "# Read the stored results into a dataframe\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the get probability score function to get the probability of the target variable\n",
    "# ranging between 0 to 1.\n",
    "target_predicted['target'] = target_predicted['target'].apply(get_prob_score)\n",
    "\n",
    "# Print the header\n",
    "print(target_predicted.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'target' column to a float before the next step\n",
    "target_predicted['target'] = target_predicted['target'].astype(float)\n",
    "\n",
    "# Convert the predicted target values into binary values using the binary_convert function\n",
    "target_predicted_binary = target_predicted['target'].apply(binary_convert)\n",
    "\n",
    "# Display a sample of the binary predictions\n",
    "print(target_predicted_binary.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the header of the test set\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Report the performance metrics that you see. Test the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of the test labels\n",
    "test_labels = test.iloc[:,0]\n",
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix on the test set\n",
    "plot_confusion_matrix(test_labels, target_predicted_binary, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve and Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve on the test set\n",
    "plot_roc(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance metrics\n",
    "plot_metrics(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(\"Classification Report\")\n",
    "print(\"---------------------\")\n",
    "print(classification_report(test_labels, target_predicted_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of Linear Learner Model 1 using Dataset combined_csv_v1.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear learner models took a long time to run in my environment, however increasing the mini batch size from 200 to 1000 decreased processing time significantly. The results of the linear learner model on combined_csv_v1 on the test set is quite similar to the logistic regression model 1 that was trained on the same dataset. Observing the confusion matrix, very few 'Delay' classes were predicted. The model is heavily biased towards 'No Delay' which is the majority class. The extremely low recall of 0.13% and high specificity of 99.97% reflect the results from the confusion matrix. The F1-score is 0.25% and the ROC is 0.5% This is not a good model for predicting flight delays.\n",
    "\n",
    "The classification report shows an overall accuracy of 79%, which of course is the percentage of values in the majority class. The recall is perfect for 'No Delay' (class 0) at 100% and terrible for 'Delay' (class 1) at 0%. These results will be compared to model 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">combined_csv_v2.csv</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Split data into training, validation and testing sets (70% - 15% - 15%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the target column position** \n",
    "\n",
    "The dataframe must have the target value in the first column.\n",
    "\n",
    "Confirm if it is in the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is indeed in the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the train set. Stratifty the target variable for an even distribution.\n",
    "train, test_and_validate = train_test_split(df2, test_size=0.3,\n",
    "                            random_state=12, stratify=df1['target'])\n",
    "\n",
    "# Split the further into the test and validation sets\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5,\n",
    "                              random_state=12, stratify=test_and_validate['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape of the three datasets\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the classes\n",
    "print(train['target'].value_counts())\n",
    "print(test['target'].value_counts())\n",
    "print(validate['target'].value_counts())\n",
    "print()\n",
    "# As percentages\n",
    "print(train['target'].value_counts(1))\n",
    "print(test['target'].value_counts(1))\n",
    "print(validate['target'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an even distribution among the three sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use linear learner estimator to build a classifcation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a prefix for the S3 bucket directories\n",
    "prefix='lab3'\n",
    "\n",
    "# Define the train test and validation file names\n",
    "train_file='train.csv'\n",
    "test_file='test.csv'\n",
    "validate_file='validate.csv'\n",
    "\n",
    "# Initialise a connection to the S3 bucket using boto3\n",
    "s3_resource = boto3.Session().resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the three datasets to S3 by calling the upload_s3_csv function\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the Linear Learner image\n",
    "container = image_uris.retrieve('linear-learner', boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "# Set the hyperparameters for the LL model\n",
    "hyperparams = {\n",
    "    \"feature_dim\": train.shape[1] - 1, # Exclude the target column\n",
    "    \"predictor_type\": \"binary_classifier\",\n",
    "    \"mini_batch_size\": 1000} # A larger batch size of 1000 decreases training time\n",
    "\n",
    "# Define the S3 location to save model outputs\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "\n",
    "# Initialize the Linear Learner estimator using SageMaker's estimator API\n",
    "ll_2=sagemaker.estimator.Estimator(container, # Container image defined above\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1, # One training instance\n",
    "                                       instance_type='ml.c5.9xlarge', # Instance type is set\n",
    "                                       output_path=s3_output_location, # Output path defined above\n",
    "                                        hyperparameters=hyperparams, # Hyperparams defined above\n",
    "                                        sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Host the model on another instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is set up to be hosted on instance_type 'ml.c5.9xlarge' as defined in the estimator above and in the transformer object below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training data location and the content type\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "# Set the validation data location and the content type\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "# Create a dictionary to hold the training and validation data channels\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the defined data channels. \n",
    "# logs are disabled as they produce a large output\n",
    "ll_2.fit(inputs=data_channels, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Perform batch transform to evaluate the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all columns except the first one from the test dataset except the target variable (1st column)\n",
    "batch_X = test.iloc[:,1:];\n",
    "\n",
    "# Set the filename for the batch input data to be uploaded to S3\n",
    "batch_X_file='batch-in.csv'\n",
    "\n",
    "# Upload the batch input data to S3 using the previously created function\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the S3 path to save the batch transform output\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "\n",
    "# Set the S3 path for the batch input data\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "# Initialize the transformer object\n",
    "ll_2_transformer = ll_2.transformer(instance_count=1,\n",
    "                                       instance_type='ml.c5.9xlarge', # Instance type is set\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line', # Line up the results\n",
    "                                       output_path=batch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the batch transform with the initialized transformer object\n",
    "ll_2_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "\n",
    "# Wait for the batch transform job to finish processing\n",
    "ll_2_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Obtain the output results of the batch transform job from S3\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "\n",
    "# Read the stored results into a dataframe\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the get probability score function to get the probability of the target variable\n",
    "# ranging between 0 to 1.\n",
    "target_predicted['target'] = target_predicted['target'].apply(get_prob_score)\n",
    "\n",
    "# Print the header\n",
    "print(target_predicted.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'target' column to a float before the next step\n",
    "target_predicted['target'] = target_predicted['target'].astype(float)\n",
    "\n",
    "# Convert the predicted target values into binary values using the binary_convert function\n",
    "target_predicted_binary = target_predicted['target'].apply(binary_convert)\n",
    "\n",
    "# Display a sample of the binary predictions\n",
    "print(target_predicted_binary.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the header of the test set\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Report the performance metrics that you see. Test the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of the test labels\n",
    "test_labels = test.iloc[:,0]\n",
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix on the test set\n",
    "plot_confusion_matrix(test_labels, target_predicted_binary, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve and Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve on the test set\n",
    "plot_roc(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance metrics\n",
    "plot_metrics(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(\"Classification Report\")\n",
    "print(\"---------------------\")\n",
    "print(classification_report(test_labels, target_predicted_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of Linear Learner Model 2 using Dataset combined_csv_v2.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the linear learner Model 2 on combined_csv_v2 on the test set is quite similar to the logistic regression Model 2 that was trained on the same dataset, perhaps slightly better. Direct numbers are difficult to compare because the test set size is different to the on-premises model. Observing the confusion matrix, 3028 'Delay' classes were predicted. This is a big improvement from Model 1 with 65. The model is still biased towards 'No Delay' which is the majority class. The low recall of 5.88% and high specificity of 98.86% reflect the results from the confusion matrix. The F1-score is 10.67% and the ROC is 0.52 which are an improvement over Linear Learner Model 1. This is still not a good model for predicting flight delays.\n",
    "\n",
    "Comparing these results to on-premesis Model 2, the AUC is equal at 0.52, but all other metrics have improved. This is the best model trained so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build and evaluate ensemble models\n",
    "\n",
    "Write code to perform the follwoing steps:\n",
    "1. Split data into training, validation and testing sets (70% - 15% - 15%).\n",
    "2. Use xgboost estimator to build a classifcation model.\n",
    "3. Host the model on another instance\n",
    "4. Perform batch transform to evaluate the model on testing data\n",
    "5. Report the performance metrics that you see better test the model performance \n",
    "6. write down your observation on the difference between the performance of using the simple and ensemble models.\n",
    "Note: You are required to perform the above steps on the two combined datasets separatey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">combined_csv_v1.csv</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Split data into training, validation and testing sets (70% - 15% - 15%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the target column position**  \n",
    "The dataframe must have the target value in the first column.\n",
    "\n",
    "Confirm if it is in the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is indeed in the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the train set. Stratifty the target variable for an even distribution.\n",
    "train, test_and_validate = train_test_split(df1, test_size=0.3,\n",
    "                            random_state=12, stratify=df1['target'])\n",
    "\n",
    "# Split the further into the test and validation sets\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5,\n",
    "                              random_state=12, stratify=test_and_validate['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape of the three datasets\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the classes\n",
    "print(train['target'].value_counts())\n",
    "print(test['target'].value_counts())\n",
    "print(validate['target'].value_counts())\n",
    "print()\n",
    "# As percentages\n",
    "print(train['target'].value_counts(1))\n",
    "print(test['target'].value_counts(1))\n",
    "print(validate['target'].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an even distribution among the three sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use xgboost estimator to build a classifcation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a prefix for the S3 bucket directories\n",
    "prefix='lab3'\n",
    "\n",
    "# Define the train test and validation file names\n",
    "train_file='train.csv'\n",
    "test_file='test.csv'\n",
    "validate_file='validate.csv'\n",
    "\n",
    "# Initialise a connection to the S3 bucket using boto3\n",
    "s3_resource = boto3.Session().resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the three datasets to S3\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the container image for XGBoost from SageMaker's repository\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "# Set the hyperparameters for the XGBoost model\n",
    "hyperparams={\"num_round\":\"42\", # Set the number of boosting rounds\n",
    "             \"eval_metric\": \"auc\", # Area under the curve is used in validation\n",
    "             \"objective\": \"binary:logistic\"} # This is used for binary classification\n",
    "\n",
    "# Define the S3 location to save model outputs\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "\n",
    "# Initialize the XGBoost estimator using SageMaker's estimator API\n",
    "xgb_1=sagemaker.estimator.Estimator(container, # Container image defined above\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1, # One training instance\n",
    "                                       instance_type='ml.c5.9xlarge', # Instance type is set\n",
    "                                       output_path=s3_output_location, # Output path defined above\n",
    "                                        hyperparameters=hyperparams, # Hyperparams defined above\n",
    "                                        sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Host the model on another instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is set up to be hosted on instance_type 'ml.c5.9xlarge' as defined in the estimator above and in the transformer object below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training data location and the content type\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "# Set the validation data location and the content type\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "# Create a dictionary to hold the training and validation data channels\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the defined data channels. \n",
    "# logs are disabled as they produce a large output\n",
    "xgb_1.fit(inputs=data_channels, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Perform batch transform to evaluate the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all columns except the first one from the test dataset except the target variable (1st column)\n",
    "batch_X = test.iloc[:,1:];\n",
    "\n",
    "# Set the filename for the batch input data to be uploaded to S3\n",
    "batch_X_file='batch-in.csv'\n",
    "\n",
    "# Upload the batch input data to S3 using the previously created function\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the S3 path to save the batch transform output\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "\n",
    "# Set the S3 path for the batch input data\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "# Initialize the transformer object\n",
    "xgb_1_transformer = xgb_1.transformer(instance_count=1,\n",
    "                                       instance_type='ml.c5.9xlarge', # Instance type is set\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line', # Line up the results\n",
    "                                       output_path=batch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the batch transform with the initialized transformer object\n",
    "xgb_1_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "\n",
    "# Wait for the batch transform job to finish processing\n",
    "xgb_1_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Obtain the output results of the batch transform job from S3\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "\n",
    "# Read the stored results into a dataframe\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted target values into binary values using the binary_convert function\n",
    "target_predicted_binary = target_predicted['target'].apply(binary_convert)\n",
    "\n",
    "# Display a sample of the binary predictions\n",
    "print(target_predicted_binary.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the header of the test set\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Report the performance metrics that you see better test the model performance  \n",
    "The metrics for this model will be summarized in the conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of the test labels\n",
    "test_labels = test.iloc[:,0]\n",
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix on the test set\n",
    "plot_confusion_matrix(test_labels, target_predicted_binary, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve on the test set\n",
    "plot_roc(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance metrics\n",
    "plot_metrics(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(\"Classification Report\")\n",
    "print(\"---------------------\")\n",
    "print(classification_report(test_labels, target_predicted_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of XGBoost Model 1 using Dataset combined_csv_v1.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the confusion matrix, evaluation metrics, ROC curve and classification report for model XGB_1 will be compared with Model XGB_2 and discussed in more detail at the end of this notebook.\n",
    "\n",
    "A brief summary shows that XGB_1 predicts slightly more accurately on dataset csv_v1 than the linear learner. The evaluation metrics were better on most metrics for XGB_1 including the AUC. In particular, the important metric of accurately predicting 'Delay' rose substantially from 65 to 859. The only exception is specificity, which is understandable when recall improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue\">combined_csv_v2.csv</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Split data into training, validation and testing sets (70% - 15% - 15%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the target column position**  \n",
    "The dataframe must have the target value in the first column.  \n",
    "\n",
    "Confirm if it is in the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is indeed in the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the train set\n",
    "train, test_and_validate = train_test_split(df2, test_size=0.3,\n",
    "                            random_state=12, stratify=df2['target'])\n",
    "\n",
    "# Split the further into the test and validation sets\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5,\n",
    "                              random_state=12, stratify=test_and_validate['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use xgboost estimator to build a classifcation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a prefix for the S3 bucket directories\n",
    "prefix='lab3'\n",
    "\n",
    "# Define the train test and validation file names\n",
    "train_file='train.csv'\n",
    "test_file='test.csv'\n",
    "validate_file='validate.csv'\n",
    "\n",
    "# Initialise a connection to the S3 bucket using boto3\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "# Upload the three datasets to S3 by calling the previously defined function\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the container image for XGBoost from SageMaker's repository\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "# Set the hyperparameters for the XGBoost model\n",
    "hyperparams={\"num_round\":\"42\", # Set the number of boosting rounds\n",
    "             \"eval_metric\": \"auc\", # Area under the curve is used in validation\n",
    "             \"objective\": \"binary:logistic\"} # This is used for binary classification\n",
    "\n",
    "# Define the S3 location to save model outputs\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "\n",
    "# Initialize the XGBoost estimator using SageMaker's estimator API\n",
    "xgb_2=sagemaker.estimator.Estimator(container, # Container image defined above\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1, # One training instance\n",
    "                                       instance_type='ml.c5.9xlarge', # Instance type is set\n",
    "                                       output_path=s3_output_location, # Output path defined above\n",
    "                                        hyperparameters=hyperparams, # Hyperparams defined above\n",
    "                                        sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Host the model on another instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is set up to be hosted on instance_type 'ml.c5.9xlarge' as defined in the estimator above and in the transformer object below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training data location and the content type\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "# Set the validation data location and the content type\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "# Create a dictionary to hold the training and validation data channels\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the defined data channels \n",
    "# logs are disabled as they produce a large output\n",
    "xgb_2.fit(inputs=data_channels, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Perform batch transform to evaluate the model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all columns except the first one from the test dataset except the target variable (1st column)\n",
    "batch_X = test.iloc[:,1:];\n",
    "\n",
    "# Set the filename for the batch input data to be uploaded to S3\n",
    "batch_X_file='batch-in.csv'\n",
    "\n",
    "# Upload the batch input data to S3 using the previously created function\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the S3 path to save the batch transform output\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "\n",
    "# Set the S3 path for the batch input data\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "# Initialize the transformer object\n",
    "xgb_2_transformer = xgb_2.transformer(instance_count=1,\n",
    "                                       instance_type='ml.c5.9xlarge', # Instance type is set\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line', # Line up the results\n",
    "                                       output_path=batch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the batch transform with the initialized transformer object\n",
    "xgb_2_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "\n",
    "# Wait for the batch transform job to finish processing\n",
    "xgb_2_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Obtain the output results of the batch transform job from S3\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "\n",
    "# Read the stored results into a dataframe\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted target values into binary values using the binary_convert function\n",
    "target_predicted_binary = target_predicted['target'].apply(binary_convert)\n",
    "\n",
    "# Display a sample of the binary predictions\n",
    "print(target_predicted_binary.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the header of the test set\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Report the performance metrics that you see better test the model performance  \n",
    "The metrics for this model will be summarized in the conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of the test labels\n",
    "test_labels = test.iloc[:,0]\n",
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix on the test set\n",
    "plot_confusion_matrix(test_labels, target_predicted_binary, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve on the test set\n",
    "plot_roc(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance metrics\n",
    "plot_metrics(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(\"Classification Report\")\n",
    "print(\"---------------------\")\n",
    "print(classification_report(test_labels, target_predicted_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the confusion matrix, evaluation metrics, ROC curve and classification report for model 2 will be compared with model 1 and discussed at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:darkblue\">combined_csv_v2.csv</span>\n",
    "### <span style=\"color:darkblue\">Change the Binary Convert Threshold from 0.5 to 0.3</span>  \n",
    "\n",
    "It will be observed how lowering the binary convert threshold from 0.5 to 0.3 affects the metrics. Comments are provided in the conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function converts the input values into a binary value\n",
    "# according to the threshold. I have set it to 0.5 as default.\n",
    "def binary_convert(x):\n",
    "    threshold = 0.3\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predicted target values into binary values using the binary_convert function\n",
    "target_predicted_binary = target_predicted['target'].apply(binary_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix on the test set\n",
    "plot_confusion_matrix(test_labels, target_predicted_binary, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve on the test set\n",
    "plot_roc(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the performance metrics\n",
    "plot_metrics(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(\"Classification Report\")\n",
    "print(\"---------------------\")\n",
    "print(classification_report(test_labels, target_predicted_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of XGBoost Model 2 using Dataset combined_csv_v2.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the confusion matrix, evaluation metrics, ROC curve and classification report for model XGB_2 show it is the best performing model evaluated in this project (not including the random forest which is not part of the evaluation).\n",
    "\n",
    "Its results are discussed in more detail below in the final comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. write down your observation on the difference between the performance of using the simple and ensemble models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Comments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some notable differences between the linear and the ensemble methods. The linear model took fmore time to process than the XGBoost model, even though the pipeline is the same set up as the XGBoost model, apart from defining the model. I increased the mini batch size from 200 to 1000 and this improved the processing speed considerably withoout any loss in accuracy.\n",
    "\n",
    "The linear model had similar performance to the on-premises logistic regression model. In the confusion matrix, very few ‘Delay’ classes were predicted (neither correctly nor incorrectly). The overall accuracy was very close to 79% or the percentage of ‘No Delay’ values in the target variable, the recall was very low and the AUC in the ROC curve was very close to 0.5, which is not a good result.\n",
    "\n",
    "The ensemble XGBoost model performed considerably better than the linear learner on both datasets. The logical setting for the binary convert threshold is 0.5, which is what I set it too as default, meaning that if the output probability is less than 0.5 the predicted value is set to 0 or ‘no delay’. If it is greater than 0.5 then it is predicted as a 1 or a ‘delay’.\n",
    "\n",
    "At a setting of 0.5, the model using combined_csv_v2.csv dataset performed better than for dataset v1. As was explained in the on-premises notebook, the extra features incorporated in v2, i.e., the holidays and the weather data, in particular heavy snow, rain or winds combined well to improve the accuracy of the second model. This was reflected in the metrics of the two models.\n",
    "\n",
    "Model XGB_1 only predicted 859 Delays correctly, whereas XGB_2 predicted 6162, a significant improvement which is reflected in the improved recall, up from 1.67% to 11.97%. The overall accuracy and precision also improved slightly in the v2 dataset, as a result the specificity decline slightly from 99.74 to 98.41, but the overall measure, the F1-score increased significantly from 3.25% to 20.29%, a significant improvement. The AUC also had a good increase from 0.51 to 0.55. In spite of the improved metrics, I would consider this model to still be quite poor. In the classification report, The recall of the majority class is good at 98% but it is still poor for the monority class 'Delay' at 12%.\n",
    "\n",
    "Many improvements could be tried, given more time. I have mentioned those in the conclusion to the on-premises notebook, so I won’t repeat them here in detail. One simple option to improve the performance of both the linear learner and the XGBoost model is hyperparameter tuning in a grid-search. This would however increase processing time significantly. A session is limited to only 2 hours which is not enough time for a proper grid-search.\n",
    "\n",
    "As mentioned, another option in the on-premises solution is the binary convert threshold. As mentioned above, I set this to 0.5 which is the logical option. Looking at the last section of code, I change this to a setting of 0.3. This effectively predicts anything with a probability of greater than 0.3 as a 1 or a ‘delay’ class. This is manipulating the output data to increase the number of predictions of the minority class. Looking at the confusion matrices for a change in threshold from 0.5 to 0.3, the number of correctly predicted delays has increased starkly from 6162 to 20871, although this has come at a cost of fewer ‘no delays’ being correctly predicted, (190764 down to 169036). The overall accuracy has fallen from 80.27% to 77.41%, as has the precision (67.72% to 45.70%) and the specificity (98.41% to 87.21%), however the recall has risen sharply (11.97% to 40.53%) and the F1-score too (20.29% to 42.96%). The AUC in the ROC has also improved significantly from 0.55 to 0.64.\n",
    "\n",
    "Manipulating this threshold is a trade-off of Recall vs precision and overall accuracy. It depends on how critical predicting the minority class is. In this case flight delays of 15 minutes or more are not very critical in my opinion, compared to say detecting cancer in a patient. More investigation would have to be done in setting this threshold, determining its importance in the business model and deciding on the optimal setting.\n",
    "\n",
    "To conclude, the XGBoost is better than the linear learner (on-cloud) and the logistic regression models used in the on-premises notebook. It is better in all metrics over the other two models. The enhanced dataset of v2 with the added weather and holiday information also significantly improves the model’s accuracy in predicted flight delays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
